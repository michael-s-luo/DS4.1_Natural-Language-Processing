{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"DS_413_Document_Classification_Lecture.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ifTTjn64-Xzj"},"source":["*Unit 4, Sprint 1, Module 3*\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"zcea63EK-Xzm"},"source":["# Document Classification (Prepare)\n","\n","Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a [kaggle competition](https://www.kaggle.com/c/whiskey-201911/). We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n","\n","Today's all about having fun and practicing your skills. The competition will begin\n","\n","## Learning Objectives\n","* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n","* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n","* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"]},{"cell_type":"markdown","metadata":{"id":"qQ1uu46njb_7"},"source":["## Challenge -- this afternoon's lab module assignment\n","\n","1. Join Lambda School's [Whiskey Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","2. Download the data\n","3. Train a model & try: \n","    - Creating a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores to specify parameters from each level in the nested pipeline. For example, `lsi__svd__n_components` specifies the parameter `n_components` inside the `svd` pipeline, which is nested inside the `lsi` pipeline\n","    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n","4. Make a submission to Kaggle "]},{"cell_type":"markdown","metadata":{"id":"UPytzJbH-Xzn"},"source":["# 1. Text Feature Extraction & Classification Pipelines (Learn)\n","<a id=\"p1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"HbT6ZBGm-Xzo"},"source":["## Overview\n","\n","Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass your raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a pipeline without worry about other data preprocessing steps. \n","\n","*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) transforms our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time, train your vectorizer separately (ie out of the grid-searched pipeline). "]},{"cell_type":"markdown","metadata":{"id":"1k_QCMx0aEBV"},"source":["##1.1 Prepare Colab notebook"]},{"cell_type":"markdown","metadata":{"id":"V1G5XOXgZ4Li"},"source":["###1.1.1 Get Spacy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11PvjAIsJnfY","executionInfo":{"status":"ok","timestamp":1638379039541,"user_tz":480,"elapsed":32051,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"0ed39599-7151-47da-bbc6-3ae0ccf45adf"},"source":["# Locally (or on colab) let's use en_core_web_lg\n","!python -m spacy download en_core_web_md # Can do lg, takes awhile"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_md==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n","\u001b[K     |████████████████████████████████| 96.4 MB 67.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.62.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n","Building wheels for collected packages: en-core-web-md\n","  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051302 sha256=bdbac93aa3b2f466f1415ae4b821115a5ca0e262b5be7213ee936ba93efe35e8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r5wp_9s2/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n","Successfully built en-core-web-md\n","Installing collected packages: en-core-web-md\n","Successfully installed en-core-web-md-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_md')\n"]}]},{"cell_type":"markdown","metadata":{"id":"EDs9XrfWZ9r6"},"source":["###1.1.2 Restart runtime!"]},{"cell_type":"markdown","metadata":{"id":"FE0sQ55sGT2a"},"source":["###1.1.3 Imports"]},{"cell_type":"code","metadata":{"id":"Ra660bkI-Xzp","executionInfo":{"status":"ok","timestamp":1638379104905,"user_tz":480,"elapsed":1644,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# Import Statements\n","import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import spacy\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","from sklearn.pipeline import FeatureUnion, Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xuB-nPGJxyb"},"source":["### 1.1.4 Load spacy"]},{"cell_type":"code","metadata":{"id":"0lNTdQWqZxPU","executionInfo":{"status":"ok","timestamp":1638379127019,"user_tz":480,"elapsed":17808,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# load in pre-trained w2v model \n","nlp = spacy.load(\"en_core_web_md\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u4bNGlpRzbK4"},"source":["##1.2 Example NLP document classification pipeline \n","Working with the [`20newsgroups` data set](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups) available from `sklearn`, <br>we'll build a classifier that can classify news articles into 2 different categories."]},{"cell_type":"markdown","metadata":{"id":"eWAippd8321u"},"source":["### 1.2.1 Get the data set"]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-2d860ec20fad5c0c","locked":false,"schema_version":3,"solution":true,"task":false},"id":"18q4-_qs-Xzq","executionInfo":{"status":"ok","timestamp":1638379227266,"user_tz":480,"elapsed":13797,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# Dataset\n","from sklearn.datasets import fetch_20newsgroups\n","\n","# 2 categories\n","categories = ['alt.atheism',\n","              'talk.religion.misc']\n","\n","data = fetch_20newsgroups(subset='all', \n","                          remove=('headers', 'footers', 'quotes'),\n","                          random_state=42, shuffle=True,\n","                          categories=categories)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F58_GhV_NRfw"},"source":["#### 1.2.2 Examine and understand the data set!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmGX_qzFKmVn","executionInfo":{"status":"ok","timestamp":1638379239836,"user_tz":480,"elapsed":318,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"f1a1b712-defe-40d9-ce11-6f5a6919d56a"},"source":["type(data)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sklearn.utils.Bunch"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E74u5Vkea0_I","executionInfo":{"status":"ok","timestamp":1638379285772,"user_tz":480,"elapsed":390,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"da57641d-ebd7-4e3a-f63f-673a2e4128ba"},"source":["print(dir(data))\n","n_targets = len(data['target_names'])\n","print(f'\\nThere are {n_targets} target names:')\n","print(data['target_names'])\n","target_values = np.unique(data['target'])\n","print(f'\\nThe target values are {target_values}')\n","n_files = len(data['filenames'])\n","print(f'\\nThere are {n_files} data files; each contains one newsgroup post labeled 0 or 1')\n","first_filename = data.filenames[0]\n","print(f'Here is the name of the first data file\\n:{first_filename} ')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['DESCR', 'data', 'filenames', 'target', 'target_names']\n","\n","There are 2 target names:\n","['alt.atheism', 'talk.religion.misc']\n","\n","The target values are [0 1]\n","\n","There are 1427 data files; each contains one newsgroup post labeled 0 or 1\n","Here is the name of the first data file\n",":/root/scikit_learn_data/20news_home/20news-bydate-train/talk.religion.misc/84101 \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"_hsArm2jK7wE","executionInfo":{"status":"ok","timestamp":1635352274653,"user_tz":420,"elapsed":358,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"75e408bd-62ee-4f76-b792-87a44e573272"},"source":["data['DESCR']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'.. _20newsgroups_dataset:\\n\\nThe 20 newsgroups text dataset\\n------------------------------\\n\\nThe 20 newsgroups dataset comprises around 18000 newsgroups posts on\\n20 topics split in two subsets: one for training (or development)\\nand the other one for testing (or for performance evaluation). The split\\nbetween the train and test set is based upon a messages posted before\\nand after a specific date.\\n\\nThis module contains two loaders. The first one,\\n:func:`sklearn.datasets.fetch_20newsgroups`,\\nreturns a list of the raw texts that can be fed to text feature\\nextractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\\nwith custom parameters so as to extract feature vectors.\\nThe second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\\nreturns ready-to-use features, i.e., it is not necessary to use a feature\\nextractor.\\n\\n**Data Set Characteristics:**\\n\\n    =================   ==========\\n    Classes                     20\\n    Samples total            18846\\n    Dimensionality               1\\n    Features                  text\\n    =================   ==========\\n\\nUsage\\n~~~~~\\n\\nThe :func:`sklearn.datasets.fetch_20newsgroups` function is a data\\nfetching / caching functions that downloads the data archive from\\nthe original `20 newsgroups website`_, extracts the archive contents\\nin the ``~/scikit_learn_data/20news_home`` folder and calls the\\n:func:`sklearn.datasets.load_files` on either the training or\\ntesting set folder, or both of them::\\n\\n  >>> from sklearn.datasets import fetch_20newsgroups\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\')\\n\\n  >>> from pprint import pprint\\n  >>> pprint(list(newsgroups_train.target_names))\\n  [\\'alt.atheism\\',\\n   \\'comp.graphics\\',\\n   \\'comp.os.ms-windows.misc\\',\\n   \\'comp.sys.ibm.pc.hardware\\',\\n   \\'comp.sys.mac.hardware\\',\\n   \\'comp.windows.x\\',\\n   \\'misc.forsale\\',\\n   \\'rec.autos\\',\\n   \\'rec.motorcycles\\',\\n   \\'rec.sport.baseball\\',\\n   \\'rec.sport.hockey\\',\\n   \\'sci.crypt\\',\\n   \\'sci.electronics\\',\\n   \\'sci.med\\',\\n   \\'sci.space\\',\\n   \\'soc.religion.christian\\',\\n   \\'talk.politics.guns\\',\\n   \\'talk.politics.mideast\\',\\n   \\'talk.politics.misc\\',\\n   \\'talk.religion.misc\\']\\n\\nThe real data lies in the ``filenames`` and ``target`` attributes. The target\\nattribute is the integer index of the category::\\n\\n  >>> newsgroups_train.filenames.shape\\n  (11314,)\\n  >>> newsgroups_train.target.shape\\n  (11314,)\\n  >>> newsgroups_train.target[:10]\\n  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\\n\\nIt is possible to load only a sub-selection of the categories by passing the\\nlist of the categories to load to the\\n:func:`sklearn.datasets.fetch_20newsgroups` function::\\n\\n  >>> cats = [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\', categories=cats)\\n\\n  >>> list(newsgroups_train.target_names)\\n  [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train.filenames.shape\\n  (1073,)\\n  >>> newsgroups_train.target.shape\\n  (1073,)\\n  >>> newsgroups_train.target[:10]\\n  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\\n\\nConverting text to vectors\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIn order to feed predictive or clustering models with the text data,\\none first need to turn the text into vectors of numerical values suitable\\nfor statistical analysis. This can be achieved with the utilities of the\\n``sklearn.feature_extraction.text`` as demonstrated in the following\\nexample that extract `TF-IDF`_ vectors of unigram tokens\\nfrom a subset of 20news::\\n\\n  >>> from sklearn.feature_extraction.text import TfidfVectorizer\\n  >>> categories = [\\'alt.atheism\\', \\'talk.religion.misc\\',\\n  ...               \\'comp.graphics\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       categories=categories)\\n  >>> vectorizer = TfidfVectorizer()\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> vectors.shape\\n  (2034, 34118)\\n\\nThe extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\\ncomponents by sample in a more than 30000-dimensional space\\n(less than .5% non-zero features)::\\n\\n  >>> vectors.nnz / float(vectors.shape[0])\\n  159.01327...\\n\\n:func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \\nreturns ready-to-use token counts features instead of file names.\\n\\n.. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\\n.. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\\n\\n\\nFiltering text for more realistic training\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIt is easy for a classifier to overfit on particular things that appear in the\\n20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\\nhigh F-scores, but their results would not generalize to other documents that\\naren\\'t from this window of time.\\n\\nFor example, let\\'s look at the results of a multinomial Naive Bayes classifier,\\nwhich is fast to train and achieves a decent F-score::\\n\\n  >>> from sklearn.naive_bayes import MultinomialNB\\n  >>> from sklearn import metrics\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.88213...\\n\\n(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\\nthe training and test data, instead of segmenting by time, and in that case\\nmultinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\\nyet of what\\'s going on inside this classifier?)\\n\\nLet\\'s take a look at what the most informative features are:\\n\\n  >>> import numpy as np\\n  >>> def show_top10(classifier, vectorizer, categories):\\n  ...     feature_names = np.asarray(vectorizer.get_feature_names())\\n  ...     for i, category in enumerate(categories):\\n  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\\n  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\\n  ...\\n  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\\n  alt.atheism: edu it and in you that is of to the\\n  comp.graphics: edu in graphics it is for and of to the\\n  sci.space: edu it that is in and space to of the\\n  talk.religion.misc: not it you in is that and to of the\\n\\n\\nYou can now see many things that these features have overfit to:\\n\\n- Almost every group is distinguished by whether headers such as\\n  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\\n- Another significant feature involves whether the sender is affiliated with\\n  a university, as indicated either by their headers or their signature.\\n- The word \"article\" is a significant feature, based on how often people quote\\n  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\\n  wrote:\"\\n- Other features match the names and e-mail addresses of particular people who\\n  were posting at the time.\\n\\nWith such an abundance of clues that distinguish newsgroups, the classifiers\\nbarely have to identify topics from text at all, and they all perform at the\\nsame high level.\\n\\nFor this reason, the functions that load 20 Newsgroups data provide a\\nparameter called **remove**, telling it what kinds of information to strip out\\nof each file. **remove** should be a tuple containing any subset of\\n``(\\'headers\\', \\'footers\\', \\'quotes\\')``, telling it to remove headers, signature\\nblocks, and quotation blocks respectively.\\n\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(pred, newsgroups_test.target, average=\\'macro\\')\\n  0.77310...\\n\\nThis classifier lost over a lot of its F-score, just because we removed\\nmetadata that has little to do with topic classification.\\nIt loses even more if we also strip this metadata from the training data:\\n\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                       categories=categories)\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.76995...\\n\\nSome other classifiers cope better with this harder version of the task. Try\\nrunning :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\\nthe ``--filter`` option to compare the results.\\n\\n.. topic:: Recommendation\\n\\n  When evaluating text classifiers on the 20 Newsgroups data, you\\n  should strip newsgroup-related metadata. In scikit-learn, you can do this by\\n  setting ``remove=(\\'headers\\', \\'footers\\', \\'quotes\\')``. The F-score will be\\n  lower because it is more realistic.\\n\\n.. topic:: Examples\\n\\n   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\\n\\n   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\\n'"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"hfTROeEzt1oA"},"source":["### How  would you classify this post? i.e., Religion or Atheism?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yT87GZN3LMTk","executionInfo":{"status":"ok","timestamp":1638379406458,"user_tz":480,"elapsed":369,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"40b7b2fe-301d-4ba7-e0ba-7f7519552c5a"},"source":["print(type(data.data))\n","print(len(data.data))\n","print(data.data[0])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","1427\n","\n","I'm sorry, but He does not!  Ever read the FIRST commandment?\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"lMS6iu0s4a8C"},"source":["###1.2.3 Function to clean the data"]},{"cell_type":"code","metadata":{"id":"mTTyxOuB-Xzr","executionInfo":{"status":"ok","timestamp":1638379585848,"user_tz":480,"elapsed":338,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["def clean_data(text):\n","    \"\"\"\n","    Accepts a single text document and performs several regex substitutions in order to clean the document. \n","    \n","    Parameters\n","    ----------\n","    text: string or object \n","    \n","    Returns\n","    -------\n","    text: string or object\n","    \"\"\"\n","    \n","    # order of operations - apply the expression from top to bottom\n","    email_regex = r\"From: \\S*@\\S*\\s?\"\n","    non_alpha = '[^a-zA-Z]'\n","    multi_white_spaces = \"[ ]{2,}\"\n","    \n","    text = re.sub(email_regex, \"\", text)\n","    text = re.sub(non_alpha, ' ', text)\n","    text = re.sub(multi_white_spaces, \" \", text)\n","    \n","    # apply case normalization \n","    return text.lower().lstrip().rstrip()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHWWacYsCYjh","executionInfo":{"status":"ok","timestamp":1638379718803,"user_tz":480,"elapsed":335,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"a0f8acb4-9884-4e1e-d747-1bb187d762d0"},"source":["print(type(data.data))\n","print(len(data.data))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","1427\n"]}]},{"cell_type":"markdown","metadata":{"id":"qLU7NToMHGUU"},"source":["### 1.2.4 Create and run a pipeline"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"LtzyrhM--Xzr","executionInfo":{"status":"ok","timestamp":1638382227832,"user_tz":480,"elapsed":347,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# prep data, instantiate a model, create pipeline object, and run a gridsearch \n","\n","###BEGIN SOLUTION\n","# save our model input data to X\n","X = data.data #data['data']\n","\n","# save our targets/labels to y\n","y = data.target\n","\n","# clean our docs \n","X_clean = [clean_data(post) for post in X]\n","\n","# Create Pipeline Components\n","\n","# create vectorizer\n","tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=None) # data transformer \n","\n","# create classifier\n","rfc = RandomForestClassifier(random_state=42) # estimator \n","\n","# Instantiate a pipeline object -- which is a list of tuples\n","#   Each tuple specifies (name of the pipeline component, the pipeline component)\n","pipe = Pipeline([(\"vect\", tfidf), # data transformer\n","                 (\"clf\", rfc)])   # classifier \n","\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGw2hhmfI6lP","executionInfo":{"status":"ok","timestamp":1638382655699,"user_tz":480,"elapsed":423589,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"6cbca8b7-2c40-4f82-d573-60b349283d7a"},"source":["%%time\n","# create a hyper-parameter dictionary for BOTH our vectorizer and our ML model \n","# here we will determine which tfidf parameter values lead to the best performing model\n","parameters = {\n","    'vect__max_df': ( 0.75, 0.9, 1.0),\n","    'vect__min_df': ( 2, 10, 15),\n","    'vect__max_features': (500, 750, 1000),\n","    'clf__n_estimators':(10, 100, 1000),\n","    'clf__max_depth':(15, 20, 25)\n","}\n","\n","# Instantiate a GridSearchCV object\n","gs = GridSearchCV(pipe, param_grid=parameters, n_jobs=-1, cv=3, verbose=1)\n","# Note: For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. For example with n_jobs=-2, all CPUs but one are used.\n","\n","gs.fit(X_clean, y)\n","###END SOLUTION"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 243 candidates, totalling 729 fits\n","CPU times: user 21.3 s, sys: 995 ms, total: 22.3 s\n","Wall time: 7min 3s\n"]}]},{"cell_type":"markdown","metadata":{"id":"2fkn8N8RQyLS"},"source":["Establishing a baseline accuracy with a naive model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8CtJ3tYNUWX","executionInfo":{"status":"ok","timestamp":1638381233087,"user_tz":480,"elapsed":338,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"8b56f574-c922-4bab-f404-a89c954ddc65"},"source":["frac_ones = y.sum()/len(y)\n","frac_ones"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4400840925017519"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"H1RoV5VmQ_IY"},"source":["Since the majority class is zeros, naive model is to predict all zeros!"]},{"cell_type":"code","metadata":{"id":"_onhKqPpRDPV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638381271000,"user_tz":480,"elapsed":404,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"91ce9252-ae53-466f-e23d-6af708663c0e"},"source":["y_naive_pred = np.zeros((1,len(y)))"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"k2ot57oTRVgO"},"source":["Naive model error, if we predict all zeros"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gdzoMVgR1Ab","executionInfo":{"status":"ok","timestamp":1638381352799,"user_tz":480,"elapsed":342,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"96d21946-0267-4595-d7dd-b99ececf2145"},"source":["frac_error = np.abs(y_naive_pred - y).sum()/len(y)\n","print(frac_error)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4400840925017519\n"]}]},{"cell_type":"markdown","metadata":{"id":"A1aI4d2xRYL6"},"source":["Naive model accuracy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCsGDTerSTlo","executionInfo":{"status":"ok","timestamp":1638381392188,"user_tz":480,"elapsed":331,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"c02b3e8c-0e4c-49f5-eed7-96686c38c0a5"},"source":["baseline_accuracy = 1-frac_error\n","print(baseline_accuracy)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0.559915907498248\n"]}]},{"cell_type":"markdown","metadata":{"id":"7PruqYynQqHA"},"source":["Pipeline results after hyperparameter tuning!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LepOoI_qNZm-","executionInfo":{"status":"ok","timestamp":1638383111836,"user_tz":480,"elapsed":156,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"f61be5b3-01c9-4199-ac1f-dbfac216cf98"},"source":["gs.best_score_"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7098732124428718"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykKsZC27NdoF","executionInfo":{"status":"ok","timestamp":1638383118957,"user_tz":480,"elapsed":293,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"83794444-138e-42e7-de61-94973f14867d"},"source":["gs.best_params_"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clf__max_depth': 25,\n"," 'clf__n_estimators': 1000,\n"," 'vect__max_df': 0.75,\n"," 'vect__max_features': 750,\n"," 'vect__min_df': 2}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puhDF0KrN-Vv","executionInfo":{"status":"ok","timestamp":1638381448275,"user_tz":480,"elapsed":375,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"c87bff16-6ee9-4d7f-e5f2-2d0f2ec64a57"},"source":["best_model = gs.best_estimator_\n","best_model"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('vect',\n","                 TfidfVectorizer(max_df=0.75, max_features=500, min_df=10,\n","                                 stop_words='english')),\n","                ('clf', RandomForestClassifier(max_depth=20, random_state=42))])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"_67VDlqCQisM"},"source":["Getting your predictions using the pipeline"]},{"cell_type":"code","metadata":{"id":"1zpAdn_6NqTs","executionInfo":{"status":"ok","timestamp":1638381472851,"user_tz":480,"elapsed":346,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# because the vectorizer was included in the pipeline object\n","# we can simply pass in raw text data into gs and it will provide a classification\n","y_pred = gs.predict(X_clean)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pDl_ssMN234","executionInfo":{"status":"ok","timestamp":1638381475095,"user_tz":480,"elapsed":9,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"27d91121-9485-410a-fcc4-7f762acfd4fc"},"source":["# this is what you would submit to Kaggle\n","y_pred\n"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, ..., 1, 1, 0])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QvQtrtcuUBi","executionInfo":{"status":"ok","timestamp":1638381483141,"user_tz":480,"elapsed":346,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"9a1fb97a-71a4-445a-aaf0-70fd289aed2f"},"source":["print(len(y_pred))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["1427\n"]}]},{"cell_type":"markdown","metadata":{"id":"r0fnovIV-Xzu"},"source":["#2. Topic Modeling via Latent Semantic Analysis (LSA)\n","a.k.a. Latent Semantic Indexing (LSI)\n","<a id=\"p2\"></a>"]},{"cell_type":"markdown","metadata":{"id":"4LMo4MRC-Xzv"},"source":["## Overview\n","Below is an excellent visual representation of *Latent Semantic Indexing*, also known as LSI, and as *Latent Semantic Analyis*, or LSA.<br>\n","Latent Semantic Indexing is a technique for Topic  Modeling, i.e. grouping a corpus of documents into similar clusters that can then be examined for topics. In the graphic below read \"context\" as \"topics\"<br>\n","\n","Grouping documents into clusters with different topics is also a form of dimensionality reduction, because the document can be represented by a vector of topics instead of a vector of tokens. <br>\n","\n","If your document-term matrix has $m$ documents and $n$ terms, <br>and the number of topics you want to find is $k$, then:\n","- The Term-Document Matrix is $n\\times m$ (the transpose of the Document-Term Matrix)\n","- The Word Assignment to Topics Matrix is $n \\times k$\n","- The Topic Importance Matrix is $k \\times k$\n","- The Topic Distribution Across Documents Matrix is $k \\times m$"]},{"cell_type":"markdown","metadata":{"id":"GQmJymbk-Xzv"},"source":["[](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1538411402/image3_maagmh.png)"]},{"cell_type":"markdown","metadata":{"id":"pSb5SvNni67-"},"source":["![](https://media.geeksforgeeks.org/wp-content/uploads/20210406165951/Screenshot20210406165933.png)<br>\n","Image Credit: [Geeks for Geeks](https://media.geeksforgeeks.org/)"]},{"cell_type":"markdown","metadata":{"id":"V2Xip-aF5Bqn"},"source":["The image above shows a decomposition of the term-document matrix into a product of three matrices.<br>\n","\n","- word = term (token or lemma)\n","- context means \"topic\" or document grouping\n","\n","\n","In the term-document matrix, the columns are vector representations of documents\n","\n","In the words-context matrix, the columns represent relative weighting of words for each topic\n","\n","In the context-document matrix, the columns represent relative weighting of topics for each document \n"]},{"cell_type":"markdown","metadata":{"id":"TFQQ9Zs_OhE_"},"source":["**Take Aways:** LSA has two main benefits\n","\n","1. Dimensionality Reduction (because you can choose the number of topics $k \\ll n$)\n","2. Topic Modeling is a form of feature engineering, because it identifies latent (hidden) topics that are present in our doc-term matrix. <br>\n","This is something that counting vectorizers can't do (i.e. `CountVectorizer`, `TfidfVEctorizer`)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"O2OQjld_-Xzv","executionInfo":{"status":"ok","timestamp":1632938573275,"user_tz":420,"elapsed":171,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"0999758f-f81c-4144-e633-85cf17f82d60"},"source":["from IPython.display import YouTubeVideo\n","YouTubeVideo('OvzJiur55vo', width=1024, height=576)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <iframe\n","            width=\"1024\"\n","            height=\"576\"\n","            src=\"https://www.youtube.com/embed/OvzJiur55vo\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.YouTubeVideo at 0x7ff74a6aba90>"],"image/jpeg":"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\n"},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"4oFb4L6_-Xzw"},"source":["## 2.1 An example of Latent Semantic Analysis\n","\n","Before we apply Latent Semantic Analysis in a pipeline, let's work through a simple example together in order to better understand how LSA works and develop an intuition along the way. \n","\n","First, if you haven't already, watch the short video provided above. We will be implementing the example from the video in our notebook. "]},{"cell_type":"code","metadata":{"id":"URNyczca-Xzw","executionInfo":{"status":"ok","timestamp":1638383346395,"user_tz":480,"elapsed":334,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# Import\n","\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","svd = TruncatedSVD(n_components=2, # number of topics to generate (also the size of the new feature space)\n","                   algorithm='randomized',\n","                   n_iter=10)\n","\n","# let's use the same data that was used in the video for consistancy \n","\n","        # topic 1 data \n","data = [\"pizza\", \n","        \"pizza hamburger cookie\",\n","        \"hamburger\", \n","        # topic 2 data\n","        \"ramen\", \n","        \"sushi\", \n","        \"ramen sushi\"]"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-74a4478e1d50513b","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"6gA7-iDx-Xzx","executionInfo":{"status":"ok","timestamp":1638383361959,"user_tz":480,"elapsed":348,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"30a6d805-22cf-4656-d5ee-002f60cd25ba"},"source":["# CREATE Term-Frequency matrix \n","\n","###BEGIN SOLUTION\n","# use CountVectorizer to create a Term-Frequency matrix (a.k.a. Doc-Term Matrix )\n","tf_vectorizer = CountVectorizer()\n","tfm = tf_vectorizer.fit_transform(data)\n","tfm = pd.DataFrame(data=tfm.toarray(), columns=tf_vectorizer.get_feature_names())\n","\n","# switch integer indices with terms\n","tfm.index = data\n","tfm\n","###END SOLUTION"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cookie</th>\n","      <th>hamburger</th>\n","      <th>pizza</th>\n","      <th>ramen</th>\n","      <th>sushi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pizza</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>pizza hamburger cookie</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hamburger</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>ramen</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>sushi</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>ramen sushi</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        cookie  hamburger  pizza  ramen  sushi\n","pizza                        0          0      1      0      0\n","pizza hamburger cookie       1          1      1      0      0\n","hamburger                    0          1      0      0      0\n","ramen                        0          0      0      1      0\n","sushi                        0          0      0      0      1\n","ramen sushi                  0          0      0      1      1"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-cfc0e060c5491e20","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{"base_uri":"https://localhost:8080/"},"id":"u29NFf0z-Xzx","executionInfo":{"status":"ok","timestamp":1638383487045,"user_tz":480,"elapsed":335,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"d8d87eca-8d49-4a9d-f5f5-da783114461c"},"source":["# Use Singular Value Decomposition (SVD)to transform our Term-Frequency matrix into a Topic matrix with reduced dimensionality\n","# LSA is just an application of SVD\n","\n","\n","###BEGIN SOLUTION\n","# Use SVD to transform our Term-Frequency matrix into a Topic matrix with reduced dimensionality\n","X_reduced = svd.fit_transform(tfm)\n","\n","# this is the output of SVD\n","# same number of rows \n","# number of features has been reduced to 2 \n","X_reduced.round(2)\n","###END SOLUTION"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.63, -0.  ],\n","       [ 1.72, -0.  ],\n","       [ 0.63,  0.  ],\n","       [ 0.  ,  0.71],\n","       [ 0.  ,  0.71],\n","       [ 0.  ,  1.41]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-f93d7b170dec7dfd","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"6o9vAW28-Xzy","executionInfo":{"status":"ok","timestamp":1638383561679,"user_tz":480,"elapsed":167,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"329b93a1-ccf6-468d-dc57-9572be0ab565"},"source":["# let's move X_reduced into a dataframe and rename the indices and columns for interpretability  \n","\n","###BEGIN SOLUION\n","# let's move X_reduced into a dataframe and rename the indices and columns for interpretability  \n","topic_cols = [\"topic_1\", \"topic_2\"]\n","dtm_reduced = pd.DataFrame(data=X_reduced.round(2), columns=topic_cols)\n","dtm_reduced.index = data\n","dtm_reduced\n","###END SOLUTION"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_1</th>\n","      <th>topic_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pizza</th>\n","      <td>0.63</td>\n","      <td>-0.00</td>\n","    </tr>\n","    <tr>\n","      <th>pizza hamburger cookie</th>\n","      <td>1.72</td>\n","      <td>-0.00</td>\n","    </tr>\n","    <tr>\n","      <th>hamburger</th>\n","      <td>0.63</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>ramen</th>\n","      <td>0.00</td>\n","      <td>0.71</td>\n","    </tr>\n","    <tr>\n","      <th>sushi</th>\n","      <td>0.00</td>\n","      <td>0.71</td>\n","    </tr>\n","    <tr>\n","      <th>ramen sushi</th>\n","      <td>0.00</td>\n","      <td>1.41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        topic_1  topic_2\n","pizza                      0.63    -0.00\n","pizza hamburger cookie     1.72    -0.00\n","hamburger                  0.63     0.00\n","ramen                      0.00     0.71\n","sushi                      0.00     0.71\n","ramen sushi                0.00     1.41"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"ZhcqeW6y8GGW"},"source":["## 2.2 Build a Latent Semantic Analysis (LSA) pipeline\n","Now that we've gone through an example of applying LSA on a small dataset, <br>let's implement it in a classification pipeline to run on the `20newsgroups`data. <br>\n","In this case we are only using LSA for dimensionality reduction.\n"]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-0ff7ed88cbc5eb32","locked":false,"schema_version":3,"solution":true,"task":false},"id":"61evvltl-Xzy","executionInfo":{"status":"ok","timestamp":1638383999630,"user_tz":480,"elapsed":339,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# build a pipeline, incorporate SVD, and run a gridsearch \n","\n","###BEGIN SOLUTION -- ask svd to truncate to the best 100 principal components, i.e. find 100 \"topics\"\n","svd = TruncatedSVD(n_components=None, \n","                   algorithm='randomized',\n","                   n_iter=10)\n","\n","# instantiate a pipeline object\n","lsi = Pipeline([(\"vect\", tfidf), # creating our term-doc matrix\n","                (\"svd\", svd)]) # apply svd to our term-doc matrix \n","\n","# instantiate a pipeline object\n","pipe = Pipeline([(\"lsi\", lsi), # data transform\n","                 (\"clf\", rfc)]) # estimator \n","\n","# a nice default starter set for hyper-parameter values\n","# include more parameters and values to try to increase model performance \n","params = { \n","    'lsi__svd__n_components': [10, 100, 200],\n","    'lsi__vect__max_df':[.95,  1.0],\n","    'clf__n_estimators':[100, 300, 1000], \n","    'clf__max_depth':(15, 20)\n","}\n","\n","\n","gs = GridSearchCV(pipe,\n","                  param_grid=params, \n","                  cv=3, \n","                  n_jobs=-1, \n","                  verbose=1 )\n","\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAQlfwOXRree","executionInfo":{"status":"ok","timestamp":1638384204888,"user_tz":480,"elapsed":181943,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"8c5c8d8c-d6a6-41db-b218-31c69d6a82aa"},"source":["%%time\n","gs.fit(X_clean, y)\n","###END SOLUTION"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 36 candidates, totalling 108 fits\n","CPU times: user 15.4 s, sys: 3.11 s, total: 18.6 s\n","Wall time: 3min 1s\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=Pipeline(steps=[('lsi',\n","                                        Pipeline(steps=[('vect',\n","                                                         TfidfVectorizer(stop_words='english')),\n","                                                        ('svd',\n","                                                         TruncatedSVD(n_components=100,\n","                                                                      n_iter=10))])),\n","                                       ('clf',\n","                                        RandomForestClassifier(random_state=42))]),\n","             n_jobs=-1,\n","             param_grid={'clf__max_depth': (15, 20),\n","                         'clf__n_estimators': [100, 300, 1000],\n","                         'lsi__svd__n_components': [10, 100, 200],\n","                         'lsi__vect__max_df': [0.95, 1.0]},\n","             verbose=1)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"FjRKarGlu7zm"},"source":["What results can we get from the `gs` object?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWzKatW2ckuo","executionInfo":{"status":"ok","timestamp":1638384247534,"user_tz":480,"elapsed":344,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"3e6f588a-ce3b-463a-d216-be32fccb8cc9"},"source":["dir(gs)"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__abstractmethods__',\n"," '__class__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__getstate__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__le__',\n"," '__lt__',\n"," '__module__',\n"," '__ne__',\n"," '__new__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__setstate__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_abc_impl',\n"," '_check_feature_names',\n"," '_check_n_features',\n"," '_check_refit_for_multimetric',\n"," '_estimator_type',\n"," '_format_results',\n"," '_get_param_names',\n"," '_get_tags',\n"," '_more_tags',\n"," '_pairwise',\n"," '_repr_html_',\n"," '_repr_html_inner',\n"," '_repr_mimebundle_',\n"," '_required_parameters',\n"," '_run_search',\n"," '_select_best_index',\n"," '_validate_data',\n"," 'best_estimator_',\n"," 'best_index_',\n"," 'best_params_',\n"," 'best_score_',\n"," 'classes_',\n"," 'cv',\n"," 'cv_results_',\n"," 'decision_function',\n"," 'error_score',\n"," 'estimator',\n"," 'fit',\n"," 'get_params',\n"," 'inverse_transform',\n"," 'multimetric_',\n"," 'n_features_in_',\n"," 'n_jobs',\n"," 'n_splits_',\n"," 'param_grid',\n"," 'pre_dispatch',\n"," 'predict',\n"," 'predict_log_proba',\n"," 'predict_proba',\n"," 'refit',\n"," 'refit_time_',\n"," 'return_train_score',\n"," 'score',\n"," 'score_samples',\n"," 'scorer_',\n"," 'scoring',\n"," 'set_params',\n"," 'transform',\n"," 'verbose']"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3aOnBOMPlBp","executionInfo":{"status":"ok","timestamp":1638384272476,"user_tz":480,"elapsed":313,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"f6e2d846-54d3-46a2-bd66-57c545a75638"},"source":["gs.best_params_"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clf__max_depth': 15,\n"," 'clf__n_estimators': 1000,\n"," 'lsi__svd__n_components': 100,\n"," 'lsi__vect__max_df': 1.0}"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"-SU2uH3hhXDg"},"source":["Using LSA, we got a slightly better score than before"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5DntWTP9PpTo","executionInfo":{"status":"ok","timestamp":1638384294056,"user_tz":480,"elapsed":300,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"8e51c52b-62e9-4f35-f8c1-b1a414213f5f"},"source":["gs.best_score_"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7196933510246204"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"up_BlkQg-Xzz"},"source":["## Challenge\n","\n","Be able to apply Latent Semantic Indexing (LSI) to various datasets. "]},{"cell_type":"markdown","metadata":{"id":"_msTRGxU-Xzz"},"source":["#3. Word Embeddings with Spacy (Learn)\n","In this section we'll complete our preparation for Lambda School's [Whiskey Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","<a id=\"p3\"></a>"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":true,"id":"P5XoeJoP-Xzz"},"source":["## Follow Along\n","Join the [Whiskey Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)"]},{"cell_type":"markdown","metadata":{"id":"QvrgCtF4-Xzz"},"source":["## 3.1 Get the data\n","- Download the [data](https://www.kaggle.com/c/whiskey-201911/data) to your local machine\n","- Upload the data from your local machine to your Colab notebook by first clicking the **folder icon** in the left sidebar, then clicking the **folder icon with the white up arrow** that appears directly under \"Files\" in the left sidebar, then selecting the `whiskey-201911.zip` file. That file's icon should now appear in the left sidebar.\n","- To get the path to `whiskey-201911.zip` in the Colab environment, hover over its icon, click the three vertical dots that appear on the right, then select \"Copy path\".\n","- Finally, unzip `whiskey-201911.zip` and read the `.csv` files.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfDaO6Em3xCi","executionInfo":{"status":"ok","timestamp":1638384510483,"user_tz":480,"elapsed":360,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"6e5c16d4-0b02-4613-8ca3-2028cac34682"},"source":["!unzip '/content/whiskey-201911.zip'\n","test = pd.read_csv('test.csv')\n","train = pd.read_csv('train.csv')"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/whiskey-201911.zip\n","  inflating: sample_submission.csv   \n","  inflating: test.csv                \n","  inflating: train.csv               \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"NTsnRcuGph1o","executionInfo":{"status":"ok","timestamp":1638384528321,"user_tz":480,"elapsed":415,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"adcf1e12-d6e4-4403-ba89-91c153f37ba4"},"source":["train"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>There have been some legendary Bowmores from t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>This bottling celebrates master distiller Park...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>What impresses me most is how this whisky evol...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>A caramel-laden fruit bouquet, followed by une...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2581</th>\n","      <td>4146</td>\n","      <td>Earthy, fleshy notes with brooding grape notes...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2582</th>\n","      <td>4153</td>\n","      <td>With its overt floral perfume notes and the sc...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2583</th>\n","      <td>4154</td>\n","      <td>An unaged whiskey from Carroll County, Iowa, w...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2584</th>\n","      <td>4155</td>\n","      <td>Fiery peat kiln smoke, tar, and ripe barley on...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2585</th>\n","      <td>4157</td>\n","      <td>Although it’s not on the label, Cavalry uses t...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2586 rows × 3 columns</p>\n","</div>"],"text/plain":["        id                                        description  category\n","0        1  A marriage of 13 and 18 year old bourbons. A m...         2\n","1        2  There have been some legendary Bowmores from t...         1\n","2        3  This bottling celebrates master distiller Park...         2\n","3        4  What impresses me most is how this whisky evol...         1\n","4        9  A caramel-laden fruit bouquet, followed by une...         2\n","...    ...                                                ...       ...\n","2581  4146  Earthy, fleshy notes with brooding grape notes...         1\n","2582  4153  With its overt floral perfume notes and the sc...         4\n","2583  4154  An unaged whiskey from Carroll County, Iowa, w...         3\n","2584  4155  Fiery peat kiln smoke, tar, and ripe barley on...         1\n","2585  4157  Although it’s not on the label, Cavalry uses t...         2\n","\n","[2586 rows x 3 columns]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vQaYqOnpnyi","executionInfo":{"status":"ok","timestamp":1635357076098,"user_tz":420,"elapsed":364,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"0cef0b49-ed6d-480d-96a9-ea224c15095f"},"source":["train['category'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1637\n","2     449\n","3     300\n","4     200\n","Name: category, dtype: int64"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"3nNUOqjrmSjB"},"source":["##3.2 Build, train, and evaluate a document classifier on the whiskey reviews!\n","As practice for this afternoon's module assignment, we'll run a Random Forest classification model on the Whiskey data set and get a preliminary result<br><br>\n","Unlike in our work in Sections 1 and 2 above, this time we'll train our classifer on document vectors derived from `spaCy`<br><br>\n","Question: <br>\n","Does `spaCy` use `CountVectorizer()`, `TfidfVectorizer()` or `word2vec` to vectorize text?<br><br>\n","\n","*Note: It would also be interesting to use `spaCy` to vectorize the `20newsgroups` data, <br>\n","then run the same pipelines as in Sections $1$ and $2$ above and compare the resulting accuracies.*\n"]},{"cell_type":"markdown","metadata":{"id":"k8cTw2ABb15G"},"source":[""]},{"cell_type":"code","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-30f6f3d27deb63a3","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{"base_uri":"https://localhost:8080/"},"id":"9w3ihOt0-Xz0","executionInfo":{"status":"ok","timestamp":1638384752509,"user_tz":480,"elapsed":62214,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"c305134d-7eb7-4819-e375-2c405c00e7fb"},"source":["%%time\n","# build a model that is trained on word vectors \n","\n","###BEGIN SOLUTION\n","def get_word_vectors(docs):\n","    \"\"\"\n","    This serves as both our tokenizer and vectorizer. \n","    Returns a list of document vectors, i.e. our doc-term matrix\n","    \"\"\"\n","    return [nlp(doc).vector for doc in docs]\n","    \n","\n","# raw text data for train and test sets\n","X_train_text = train[\"description\"]\n","X_test_text = test[\"description\"]\n","\n","# transform raw data into doc-term matrices for train and test sets \n","X_train = get_word_vectors(X_train_text)\n","X_test = get_word_vectors(X_test_text)\n","\n","# save ratings to y vector\n","y_train = train[\"category\"]\n","\n"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1min 2s, sys: 175 ms, total: 1min 2s\n","Wall time: 1min 2s\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tp12BtAM4_bj","executionInfo":{"status":"ok","timestamp":1635357400257,"user_tz":420,"elapsed":445,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"d3d6bc82-2dd3-44ff-9b18-e66b49ac4fc6"},"source":["print(len(X_train))\n","print(len(X_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2586\n","288\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rGDYDUC8Z4T"},"source":["Questions: \n","What information do the entries of of `X_train` contain? <br>\n","Why does each element in `X_train` have the following shape?<br>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47ajpFUJ5gP9","executionInfo":{"status":"ok","timestamp":1638384895553,"user_tz":480,"elapsed":381,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"d46375ea-ffc0-4390-dde1-822e8567683f"},"source":["X_train[0].shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300,)"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"2dNgMJ3IbhHF"},"source":["### Fit the Whiskey reviews to a Random Forest Classifier\n","We'll fit a Random Forest model, and we will use `oob_score` (oob means \"out-of-bag\")<br>\n","for a quick estimate of the generalization performance. <br>\n","The term *bag* comes from *bootstrap aggregation*, the process of building trees for the random forest model. <br>\n","Each tree in the forest is a \"bootstrap\" sample, meaning that it's constructed by *randomly* drawing N data points <br>\n","-- *with replacement* -- from the training set. That is of course why the model is called Random Forest!<br>\n","Here $N$ is the number of data points in the training set.<br>\n","\n","For best results in this afternoon's assignment, however, you will do hyperparameter tuning using GridSearchCV "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67YghC9M440c","executionInfo":{"status":"ok","timestamp":1638385506240,"user_tz":480,"elapsed":4412,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"d89ed2f6-5a01-4094-cdf2-80d23bb945dd"},"source":["rfc = RandomForestClassifier(oob_score=True)\n","\n","rfc.fit(X_train, y_train)\n"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(oob_score=True)"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"mZJgNuLkg2GY"},"source":["The training accuracy is perfect, due to massive overfitting!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Wg4PZaKdLZ5","executionInfo":{"status":"ok","timestamp":1638385510093,"user_tz":480,"elapsed":328,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"149770a8-9ee8-4f39-84ca-6a849d7a7dd7"},"source":["# train set accuracy -- massively overfitted!\n","rfc.score(X_train, y_train)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"awQWIxsFhC7w"},"source":["The out-of-bag accuracy score provides a rough estimate of the generalization error we could expect from the model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EdJRdPpdN-t","executionInfo":{"status":"ok","timestamp":1638385522516,"user_tz":480,"elapsed":320,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"29d5bcd6-12d5-4588-b39b-63758429ede0"},"source":["rfc.oob_score_"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.731245166279969"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"WHpWG3LC-Xz1"},"source":["## Challenge  -- this afternoon's lab module assignment\n","\n","1. Join Lambda School's [Whiskey Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","2. Download the data\n","3. Train and hyperparameter tune a model: \n","    - Create a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n","    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n","4. Make a submission to Kaggle \n","\n","Note: You can put together your project from code snippets from the current Colab notebook. <br>\n","Alternatively, you can adapt and refactor this [Colab notebook](https://drive.google.com/file/d/1ZY-P33tXD5y-VucOjg2TXO5OAQBWuTLf/view?usp=sharing) to work with the Kaggle data for your project."]},{"cell_type":"markdown","metadata":{"id":"2O_V1ayxyLQ9"},"source":["For the classifier model, you can try any or several of these models\n","* `RandomForestClassifier()` or `GradientBoostingClassifier()` from the `sklearn` library\n","* `XGBClassifier()` from the `xgboost` library\n","* `CatboostClassifier() from the `catboost` library\n","* `LGBMClassifier()` from the `lightgbm` library"]},{"cell_type":"markdown","metadata":{"id":"CU7Oep--uLPR"},"source":["# Post Lecture Assignment (Stretch)\n","<a id=\"p4\"></a>\n","\n","Your primary assignment this afternoon is to achieve a minimum of 80% accuracy on the Kaggle competition. <br>\n","Once you've accomplished that, do (1), and either (2) or (3): \n","\n","1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n","    - What is \"Sentiment Analysis\"? \n","    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n","    - How do people create labeled sentiment data? Are those labels really sentiment?\n","    - What are common applications of sentiment analysis?\n","\n","2. Singular Value Decomposition (SVD) is one of the most important and powerful methods in Applied Mathematics and in all of Machine Learning.  Principal Components Analysis (PCA) -- which we used in Module 2 -- is closely releated to SVD. Research SVD using the resources below. Then write a few paragraphs explaining -- in your own words -- your understanding of SVD and why it has become so important in Machine Learning. As you write, pretend that you will be presenting this summary orally as an answer to a question during a job interview.<br>\n","\n","* [Daniela Witten](https://www.danielawitten.com/), a Professor of Mathematical Statistics at the University of Washington, recently penned a highly amusing and informative [tweetstorm](https://twitter.com/WomenInStat/status/1285611042446413824) about SVD, well worth reading!<br>\n","* [Stanford University Lecture on SVD](https://www.youtube.com/watch?v=P5mlg91as1c) <br>\n","* [StatQuest Principal Components Analysis](https://www.youtube.com/watch?v=FgakZw6K1QQ)<br>\n","* [Luis Serrano Principal Components Analysis](https://www.youtube.com/watch?v=g-Hb26agBFg)<br>\n","\n","3. Research which other models can be used for text classification -- see [Multi-Class Text Classification Model Comparison and Selection](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568)\n","  - Try a few other classical machine learning models, and compare with the gradient boosting results \n","  - Neural Networks are becoming more popular for document classification. Why is that the case? \n","  - If you have the time and interest, check out this [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google\n","   "]}]}